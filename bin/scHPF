#! /usr/bin/env python

import os
import argparse

import numpy as np
import pandas as pd
from scipy.io import mmread, mmwrite
from scipy.sparse import coo_matrix
from sklearn.externals import joblib

from schpf import scHPF
import schpf.preprocessing as pp

def _parser():
    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers(dest='cmd')

    ### Preprocess command
    prep = subparsers.add_parser('prep')
    prep.add_argument('-i', '--input', required=True,
            help='Input data. Currently accepts whitespace-delimited gene '
            'by cell count matrices with 2 leading columns of gene '
            'attributes, assumed to be ENSEMBL_ID and GENE_SYMBOL '
            'respectively, or loom files with row attribute `Gene`, which '
            'is a gene symbol.'
            )
    prep.add_argument('-o', '--outdir', required=True,
            help='Directory in which to prepared files')
    prep.add_argument('-m', '--min-cells', type=float, default=0.01, 
            help='Minimum number of cells in which we must observe at '
            'least one transcript of a gene for the gene to pass '
            'filtering. If 0 < `min_cells` < 1, sets threshold to be '
            '`min_cells` * ncells, rounded to the nearest integer.')
    prep.add_argument('-w', '--whitelist', default='',
            help='File where first column is list of ENSEMBL gene ids to '
            'accept, and second column is gene symbol. Only performed if '
            'file given. Superseded by blacklist')
    prep.add_argument('-b', '--blacklist', default='',
            help='File where first column is list of ENSEMBL gene ids to '
            'exclude, and second column is gene symbol. Only performed if '
            'file given. Supersedes whitelist.')
    prep.add_argument('--filter-by-gene-name', default=False, 
            action='store_true', help='Use gene symbol rather than ENSEMBL '
            'id to filter (with whitelist or blacklist).  Useful for '
            'datasets where only gene symbols are given. Applies to both '
            'whitelist and blacklist. Used by default when input is a loom '
            'file.')
    prep.add_argument('--no-split-on-dot', default=False, action='store_true',
            help='Don\'t split gene symbol or name on period before '
            'filtering. We do this by default for ENSEMBL ids.')

    ###### Train command
    train = subparsers.add_parser('train')
    # data and saving
    train.add_argument('-i', '--input', required=True,
            help='Training data. Expects either an mtx file (rows are cells, '
            ' columns are genes, values are UMI counts) or a tab-separated '
            'file formatted like:' '`CELL_ID    GENE_ID    UMI_COUNT`. If '
            'a tab-separated file give, assumed to be 0 indexed and have no '
            'duplicate entries.'
            )
    train.add_argument('-o', '--outdir', required=True,
            help='Directory in which to save scHPF model. Will be created'
            'if does not exist.')
    train.add_argument('-v', '--validation', 
            help='Validation data. Must have same format (either mtx or tsv) '
            'as args.input' )

    # Require model hyperparameter
    train.add_argument('-k', '--nfactors', type=int, required=True,
            help='Number of factors.')

    # training parameters
    train.add_argument('--quiet', dest='verbose', action='store_false', 
            default=True)
    train.add_argument('-t', '--ntrials',  type=int, default=1,
            help='Number of times to run scHPF, selecting the trial with '
            'best loss on the validation set, if given, or the best loss '
            'on the training set if no validation set is given.')
    train.add_argument('-M', '--max-iter', type=int, default=1000,
            help='Maximum iterations. Default 1000.')
    train.add_argument('-m', '--min-iter', type=int, default=30,
            help='Minimum iterations. Default 30')
    train.add_argument('-e',  '--epsilon', type=float, default=0.001,
            help='Minimum percent decrease in loss between checks to continue '
            'inference (convergence criteria). [Default 0.001].')
    train.add_argument('-f', '--check_freq', type=int, default=10,
            help='Number of iterations to run between convergence checks. '
            'Default 10.')
    train.add_argument('-bna', '--better-than-n-ago', default=5, type=int,
            help= 'Stop condition if loss is getting worse.  Stops training '
            'if loss is worse than `better_than_n_ago`*`check_freq` training steps '
            'ago and getting worse. Normally not necessary to change.')


    ### Score command
    score = subparsers.add_parser('score')
    score.add_argument('-m', '--model', required=True,
            help='Saved scHPF model.  Should have extension `.joblib`')
    score.add_argument('-o', '--outdir', required=True,
            help='Directory in which to save score files')
    score.add_argument('-g', '--genefile', default=None,
            help='If given, create an additonal file with genes ranked by '
            'score for each factor.  Expected to be a two-column, tab-'
            'delimited file where the first column is the ENSEMBL id (but '
            'could be anything) and the second column is the gene symbol.')

    return parser


if __name__=='__main__':
    parser = _parser()
    args = parser.parse_args()

    if not os.path.exists(args.outdir):
        os.makedirs(args.outdir)

    if args.cmd == 'prep':
        print('Loading data...')
        if args.input.endswith('.loom'):
            umis, genes = pp.load_loom(args.input)
            candidate_names = genes['Gene']
            genelist_col = 1
        else:
            umis, genes = pp.load_txt(args.input)
            genelist_col = 1 if args.filter_by_gene_name else 0
            candidate_names = genes[genelist_col]

        print('Generating masks for filtering...')
        mask = pp.min_cells_expressing_mask(umis, args.min_cells)
        if args.whitelist is not None and len(args.whitelist):
            whitelist = pd.read_csv(args.whitelist, delim_whitespace=True,
                    header=None)
            mask &= pp.genelist_mask(candidate_names, whitelist[genelist_col],
                        split_on_dot = ~args.no_split_on_dot)
        if args.blacklist is not None and len(args.blacklist):
            blacklist = pd.read_csv(args.whitelist, delim_whitespace=True,
                    header=None)
            mask &= pp.genelist(candidate_names, blacklist[genelist_col],
                        whitelist=False, split_on_dot = ~args.no_split_on_dot)

        print('Filtering data...')
        # TODO : don't convert back to dense
        genes = genes.loc[mask]
        umis_dense = umis.toarray()[:, mask]
        nz = np.nonzero(umis_dense)
        filtered = coo_matrix((umis_dense[nz], nz))

        print('Writing filtered data to file...')
        mmwrite('{}/train.mtx'.format(args.outdir), filtered, field='integer')
        genes.to_csv('{}/genes.txt'.format(args.outdir), sep='\t', header=None,
                index=None)

    elif args.cmd == 'train':
        # load data
        print( 'Loading data...' )
        load_fnc = mmread if args.input.endswith('.mtx') else pp.load_coo
        train = load_fnc(args.input)

        ngenes = train.shape[1]
        if ngenes >= 20000:
            msg = 'Warning: you are running scHPF with {} genes,'.format(ngenes)
            msg += ' which is more than the ~20k protein coding genes in the'
            msg += ' human genome. We suggest running scHPF on protein-coding' 
            msg += ' genes only.'

        if args.validation is not None:
            vdata = load_fnc(args.validation)
        else:
            vdata = None

        # create model
        print( 'Running trials...' )
        best_loss, best_model = 1e100, None
        for t in range(args.ntrials):
            model = scHPF(nfactors=args.nfactors,
                        min_iter=args.min_iter, max_iter=args.max_iter,
                        check_freq=args.check_freq, epsilon=args.epsilon,
                        better_than_n_ago=args.better_than_n_ago,
                        )
            model.fit(train, validation_data=vdata, verbose=args.verbose)

            loss = model.loss[-1]
            if loss < best_loss:
                best_model = model
                best_loss = loss
                print('New best!')

        print('Best loss: {0:.6f}'.format(best_loss))
        outname = '{}/scHPF_K{}_epsilon{}_{}trials.joblib'.format(
                args.outdir, args.nfactors, args.epsilon, args.ntrials)
        joblib.dump(best_model, outname)
    elif args.cmd == 'score':
        print('Loading model...')
        model = joblib.load(args.model)

        print('Calculating scores...')
        cell_score = model.cell_score()
        gene_score = model.gene_score()

        print('Saving scores...')
        np.savetxt(args.outdir + '/cell_score.txt', cell_score, delimiter='\t')
        np.savetxt(args.outdir + '/gene_score.txt', gene_score, delimiter='\t')

        if args.genefile is not None:
            print('Ranking genes...')
            genes = np.loadtxt(args.genefile, delimiter='\t', dtype=str)
            ranks = np.argsort(gene_score, axis=0)[::-1]
            ranked_genes = []
            for i in range(gene_score.shape[1]):
                ranked_genes.append(genes[ranks[:,i], 1])
            ranked_genes = np.stack(ranked_genes).T
            print('Saving ranked genes...')
            np.savetxt(args.outdir + '/ranked_genes.txt', ranked_genes, 
                    fmt="%s", delimiter='\t')
